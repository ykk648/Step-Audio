import gradio as gr
# import torch
import torchaudio
import argparse
from tts import StepAudioTTS
from tokenizer import StepAudioTokenizer
from utils import load_audio
import os
from datetime import datetime

# ä¿®æ”¹æ¨¡å‹åœ°å€ 
model_path = "/models"
encoder = StepAudioTokenizer(f"{model_path}/Step-Audio-Tokenizer")
tts_engine = StepAudioTTS(f"{model_path}/Step-Audio-TTS-3B", encoder)

# å‡è®¾ StepAudioTTS å·²ç»åˆå§‹åŒ–
# step_audio_tts = StepAudioTTS()

# å¤„ç†æ™®é€šè¯­éŸ³åˆæˆ


# æ™®é€šè¯­éŸ³åˆæˆ
def tts_common(text,speaker, emotion, language, speed):
    text = f"({emotion})({language})({speed})" + text
    print(text)
    # speaker = "Tingting"
    # speaker = "xueqin"
    output_audio, sr = tts_engine(text, speaker)
    # è·å–å½“å‰æ—¶é—´å¹¶æ ¼å¼åŒ–æ–‡ä»¶å
    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    save_path = f"./results/common/{current_time}.wav"

    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    torchaudio.save(save_path, output_audio, sr)

    return save_path  # è¿”å›éŸ³é¢‘æ–‡ä»¶è·¯å¾„
def tts_music(text_input_rap,speaker, mode_input):
    text_input_rap = f"({mode_input})" + text_input_rap
    print(text_input_rap)
    # speaker = "Tingting"
    output_audio, sr = tts_engine(text_input_rap, speaker)

    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    save_path = f"./results/music/{current_time}.wav"

    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    torchaudio.save(save_path, output_audio, sr)

    return save_path  # è¿”å›éŸ³é¢‘æ–‡ä»¶è·¯å¾„

# å¤„ç†è¯­éŸ³å…‹éš†
def tts_clone(text, wav_file,speaker_prompt, speaker_name, emotion, language, speed):
    clone_speaker = {
        "wav_path": wav_file,
        "speaker": speaker_name,
        "prompt_text": speaker_prompt
    }
    clone_text = f"({emotion})({language})({speed})" + text
    print(clone_text)
    output_audio, sr = tts_engine(clone_text, "",clone_speaker)

    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    save_path = f"./results/clone/{current_time}.wav"

    # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
    torchaudio.save(save_path, output_audio, sr)

    return save_path  # è¿”å›éŸ³é¢‘æ–‡ä»¶è·¯å¾„

# é€‰é¡¹åˆ—è¡¨
emotion_options = ["é«˜å…´1", "é«˜å…´2", "ç”Ÿæ°”1", "ç”Ÿæ°”2", "æ‚²ä¼¤1", "æ’’å¨‡1"]
language_options = ["ä¸­æ–‡", "è‹±æ–‡", "éŸ©è¯­", "æ—¥è¯­", "å››å·è¯", "ç²¤è¯­", "å¹¿ä¸œè¯"]
speed_options = ["æ…¢é€Ÿ1", "æ…¢é€Ÿ2", "å¿«é€Ÿ1", "å¿«é€Ÿ2"]
speaker_options = ["Tingting","nezha"]

# Gradio ç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ™ï¸ Step-Audio-TTS-3B Demo")
    gr.Markdown(
        """
    <p align="center">
        <img src="assets/logo.png"  height=100>
    </p>
        """)

    with gr.Tab("æ™®é€šè¯­éŸ³åˆæˆ"):
        #å››ä¸ªè¾“å…¥å‚æ•°
        text_input = gr.Textbox(label="è¾“å…¥æ–‡æœ¬")

        # å…è®¸ç”¨æˆ·ä¸é€‰æ‹©æˆ–è€…è¾“å…¥è‡ªå®šä¹‰å€¼
        speaker_input = gr.Dropdown(speaker_options, label="é€‰æ‹©è®²è¯äººï¼ˆé»˜è®¤Tingtingï¼‰")
        emotion_input = gr.Dropdown(emotion_options, label="é€‰æ‹©æƒ…æ„Ÿï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)
        language_input = gr.Dropdown(language_options, label="é€‰æ‹©è¯­ç§/æ–¹è¨€ï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)
        speed_input = gr.Dropdown(speed_options, label="è¯­é€Ÿè°ƒæ•´ï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)

        # ç‚¹å‡»ç”Ÿæˆ
        submit_btn = gr.Button("ğŸ”Š ç”Ÿæˆè¯­éŸ³")
        #ç”Ÿæˆçš„è¯­éŸ³
        output_audio = gr.Audio(label="åˆæˆè¯­éŸ³", interactive=False)

        submit_btn.click(tts_common, inputs=[text_input, speaker_input,emotion_input, language_input, speed_input], outputs=output_audio)



    with gr.Tab("RAP / å“¼å”±æ¨¡å¼"):
        text_input_rap = gr.Textbox(label="è¾“å…¥æ–‡æœ¬")
        speaker_input = gr.Dropdown(speaker_options, label="é€‰æ‹©è®²è¯äººï¼ˆé»˜è®¤Tingtingï¼‰")
        mode_input = gr.Radio(["RAP", "å“¼å”±"], label="æ¨¡å¼é€‰æ‹©")
        submit_btn_rap = gr.Button("ğŸ¤ ç”Ÿæˆ RAP / å“¼å”±")
        output_audio_rap = gr.Audio(label="åˆæˆè¯­éŸ³", interactive=False)
        submit_btn_rap.click(tts_music, inputs=[text_input_rap, speaker_input,mode_input], outputs=output_audio_rap)

    with gr.Tab("è¯­éŸ³å…‹éš†"):
        text_input_clone = gr.Textbox(label="è¾“å…¥æ–‡æœ¬")
        audio_input = gr.File(label="ä¸Šä¼ å‚è€ƒéŸ³é¢‘ (.wav)")
        speaker_prompt = gr.Textbox(label="éŸ³é¢‘prompt", placeholder="éŸ³é¢‘çš„æ–‡æœ¬å†…å®¹")
        speaker_name_input = gr.Textbox(label="ä¸ºå…‹éš†å£°éŸ³å‘½å", placeholder="å¦‚ï¼šMyVoice")

        # å…è®¸ç”¨æˆ·ä¸é€‰æ‹©æˆ–è€…è¾“å…¥è‡ªå®šä¹‰å€¼
        emotion_input = gr.Dropdown(emotion_options, label="é€‰æ‹©æƒ…æ„Ÿï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)
        language_input = gr.Dropdown(language_options, label="é€‰æ‹©è¯­ç§/æ–¹è¨€ï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)
        speed_input = gr.Dropdown(speed_options, label="è¯­é€Ÿè°ƒæ•´ï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)

        submit_btn_clone = gr.Button("ğŸ—£ï¸ ç”Ÿæˆå…‹éš†è¯­éŸ³")
        output_audio_clone = gr.Audio(label="åˆæˆè¯­éŸ³", interactive=False)
        

        submit_btn_clone.click(tts_clone, 
                               inputs=[text_input_clone, audio_input, speaker_prompt,speaker_name_input, emotion_input, language_input, speed_input], 
                               outputs=output_audio_clone)

demo.launch(server_name = "0.0.0.0",server_port=8080)
