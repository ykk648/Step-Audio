import gradio as gr
import argparse
import torchaudio
from tts import StepAudioTTS
from tokenizer import StepAudioTokenizer
from datetime import datetime

# è§£æå‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser()
parser.add_argument("--model-path", type=str, default="./models", help="Model path.")
parser.add_argument(
    "--server-port", type=int, default=8080, help="Demo server port."
)
parser.add_argument(
    "--server-name", type=str, default="0.0.0.0", help="Demo server name."
)
parser.add_argument(
    "--share", action="store_true", help="Enable sharing of the demo."
)
args = parser.parse_args()

# ä½¿ç”¨è§£æåçš„å‘½ä»¤è¡Œå‚æ•°è®¾ç½®æ¨¡å‹è·¯å¾„
model_path = args.model_path
encoder = StepAudioTokenizer(f"{model_path}/Step-Audio-Tokenizer")
tts_engine = StepAudioTTS(f"{model_path}/Step-Audio-TTS-3B", encoder)

# æ™®é€šè¯­éŸ³åˆæˆ
def tts_common(text, speaker, emotion, language, speed):
    text = f"({emotion})({language})({speed})" + text
    output_audio, sr = tts_engine(text, speaker)
    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    save_path = f"./results/common/{current_time}.wav"
    torchaudio.save(save_path, output_audio, sr)
    return save_path

# RAP / å“¼å”±æ¨¡å¼
def tts_music(text_input_rap, speaker, mode_input):
    text_input_rap = f"({mode_input})" + text_input_rap
    output_audio, sr = tts_engine(text_input_rap, speaker)
    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    save_path = f"./results/music/{current_time}.wav"
    torchaudio.save(save_path, output_audio, sr)
    return save_path

# è¯­éŸ³å…‹éš†
def tts_clone(text, wav_file, speaker_prompt, speaker_name, emotion, language, speed):
    clone_speaker = {
        "wav_path": wav_file,
        "speaker": speaker_name,
        "prompt_text": speaker_prompt
    }
    clone_text = f"({emotion})({language})({speed})" + text
    output_audio, sr = tts_engine(clone_text, "", clone_speaker)
    current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    save_path = f"./results/clone/{current_time}.wav"
    torchaudio.save(save_path, output_audio, sr)
    return save_path

# é€‰é¡¹åˆ—è¡¨
emotion_options = ["é«˜å…´1", "é«˜å…´2", "ç”Ÿæ°”1", "ç”Ÿæ°”2", "æ‚²ä¼¤1", "æ’’å¨‡1"]
language_options = ["ä¸­æ–‡", "è‹±æ–‡", "éŸ©è¯­", "æ—¥è¯­", "å››å·è¯", "ç²¤è¯­", "å¹¿ä¸œè¯"]
speed_options = ["æ…¢é€Ÿ1", "æ…¢é€Ÿ2", "å¿«é€Ÿ1", "å¿«é€Ÿ2"]
speaker_options = ["Tingting", "nezha"]

# Gradio ç•Œé¢
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ™ï¸ Step-Audio-TTS-3B Demo")
    gr.Markdown(
        """
    <p align="center">
        <img src="assets/logo.png" height=100>
    </p>
    """)

    # æ™®é€šè¯­éŸ³åˆæˆ
    with gr.Tab("æ™®é€šè¯­éŸ³åˆæˆ"):
        text_input = gr.Textbox(label="è¾“å…¥æ–‡æœ¬")
        speaker_input = gr.Dropdown(speaker_options, label="é€‰æ‹©è®²è¯äººï¼ˆé»˜è®¤Tingtingï¼‰")
        emotion_input = gr.Dropdown(emotion_options, label="é€‰æ‹©æƒ…æ„Ÿï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)
        language_input = gr.Dropdown(language_options, label="é€‰æ‹©è¯­ç§/æ–¹è¨€ï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)
        speed_input = gr.Dropdown(speed_options, label="è¯­é€Ÿè°ƒæ•´ï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)
        submit_btn = gr.Button("ğŸ”Š ç”Ÿæˆè¯­éŸ³")
        output_audio = gr.Audio(label="åˆæˆè¯­éŸ³", interactive=False)

        submit_btn.click(tts_common, inputs=[text_input, speaker_input, emotion_input, language_input, speed_input], outputs=output_audio)

    # RAP / å“¼å”±æ¨¡å¼
    with gr.Tab("RAP / å“¼å”±æ¨¡å¼"):
        text_input_rap = gr.Textbox(label="è¾“å…¥æ–‡æœ¬")
        speaker_input = gr.Dropdown(speaker_options, label="é€‰æ‹©è®²è¯äººï¼ˆé»˜è®¤Tingtingï¼‰")
        mode_input = gr.Radio(["RAP", "å“¼å”±"], label="æ¨¡å¼é€‰æ‹©")
        submit_btn_rap = gr.Button("ğŸ¤ ç”Ÿæˆ RAP / å“¼å”±")
        output_audio_rap = gr.Audio(label="åˆæˆè¯­éŸ³", interactive=False)
        submit_btn_rap.click(tts_music, inputs=[text_input_rap, speaker_input, mode_input], outputs=output_audio_rap)

    # è¯­éŸ³å…‹éš†
    with gr.Tab("è¯­éŸ³å…‹éš†"):
        text_input_clone = gr.Textbox(label="è¾“å…¥æ–‡æœ¬")
        audio_input = gr.File(label="ä¸Šä¼ å‚è€ƒéŸ³é¢‘ (.wav)")
        speaker_prompt = gr.Textbox(label="éŸ³é¢‘prompt", placeholder="éŸ³é¢‘çš„æ–‡æœ¬å†…å®¹")
        speaker_name_input = gr.Textbox(label="ä¸ºå…‹éš†å£°éŸ³å‘½å", placeholder="å¦‚ï¼šMyVoice")
        emotion_input = gr.Dropdown(emotion_options, label="é€‰æ‹©æƒ…æ„Ÿï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)
        language_input = gr.Dropdown(language_options, label="é€‰æ‹©è¯­ç§/æ–¹è¨€ï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)
        speed_input = gr.Dropdown(speed_options, label="è¯­é€Ÿè°ƒæ•´ï¼ˆå¯é€‰ï¼‰", allow_custom_value=True, interactive=True)
        submit_btn_clone = gr.Button("ğŸ—£ï¸ ç”Ÿæˆå…‹éš†è¯­éŸ³")
        output_audio_clone = gr.Audio(label="åˆæˆè¯­éŸ³", interactive=False)
        submit_btn_clone.click(tts_clone, inputs=[text_input_clone, audio_input, speaker_prompt, speaker_name_input, emotion_input, language_input, speed_input], outputs=output_audio_clone)

# å¯åŠ¨ Gradio demo
demo.launch(server_name=args.server_name, server_port=args.server_port, share=args.share)
